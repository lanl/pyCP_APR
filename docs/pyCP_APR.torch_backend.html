

<!DOCTYPE html>


<html lang="Python" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>pyCP_APR.torch_backend package &#8212; pyCP_APR 1.0.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'pyCP_APR.torch_backend';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="pyCP_APR.numpy_backend package" href="pyCP_APR.numpy_backend.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="Python"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">pyCP_APR 1.0.2 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="CP_APR.html">pyCP_APR.CP_APR API</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">pyCP_APR.datasets API</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="modules.html">pyCP_APR Package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="pyCP_APR.html">pyCP_APR package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="pyCP_APR.applications.html">pyCP_APR.applications package</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyCP_APR.numpy_backend.html">pyCP_APR.numpy_backend package</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">pyCP_APR.torch_backend package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/pyCP_APR.torch_backend.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>pyCP_APR.torch_backend package</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.CP_APR_Torch">pyCP_APR.torch_backend.CP_APR_Torch module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU"><code class="docutils literal notranslate"><span class="pre">CP_APR_MU</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU.train"><code class="docutils literal notranslate"><span class="pre">CP_APR_MU.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.ktensor_Torch">pyCP_APR.torch_backend.ktensor_Torch module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR"><code class="docutils literal notranslate"><span class="pre">K_TENSOR</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR.deep_copy_factors"><code class="docutils literal notranslate"><span class="pre">K_TENSOR.deep_copy_factors()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.sptensor_Torch">pyCP_APR.torch_backend.sptensor_Torch module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.sptensor_Torch.SP_TENSOR"><code class="docutils literal notranslate"><span class="pre">SP_TENSOR</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend">Module contents</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="pycp-apr-torch-backend-package">
<h1>pyCP_APR.torch_backend package<a class="headerlink" href="#pycp-apr-torch-backend-package" title="Permalink to this heading">#</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading">#</a></h2>
</section>
<section id="module-pyCP_APR.torch_backend.CP_APR_Torch">
<span id="pycp-apr-torch-backend-cp-apr-torch-module"></span><h2>pyCP_APR.torch_backend.CP_APR_Torch module<a class="headerlink" href="#module-pyCP_APR.torch_backend.CP_APR_Torch" title="Permalink to this heading">#</a></h2>
<p>Python implementation of the CP-APR algorithm [1-4] with PyTorch backend.</p>
<p>This backend can be used to factorize sparse tensorsin COO format on GPU or CPU.</p>
<p class="rubric">References</p>
<p>[1] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.</p>
<p>[2] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, <a class="reference external" href="http://dx.doi.org/10.1145/1186785.1186794">http://dx.doi.org/10.1145/1186785.1186794</a>.</p>
<p>[3] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, <a class="reference external" href="http://dx.doi.org/10.1137/060676489">http://dx.doi.org/10.1137/060676489</a>.</p>
<p>[4] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.</p>
<p>&#64;author: Maksim Ekin Eren</p>
<dl class="py class">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyCP_APR.torch_backend.CP_APR_Torch.</span></span><span class="sig-name descname"><span class="pre">CP_APR_MU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kappa</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kappa_tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_inner_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_iters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_inner_itn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">simple_verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stoptime</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'0'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'numpy'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'torch.DoubleTensor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">follow_M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/CP_APR_Torch.html#CP_APR_MU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Initilize the CP_APR_MU class. Sets up the class variables and the CUDA for
tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) -- Prevents zero division. Default is 1e-10.</p></li>
<li><p><strong>kappa</strong> (<em>float</em><em>, </em><em>optional</em>) -- Fix slackness level. Default is 1e-2.</p></li>
<li><p><strong>kappa_tol</strong> (<em>float</em><em>, </em><em>optional</em>) -- Tolerance on slackness level. Default is 1e-10.</p></li>
<li><p><strong>max_inner_iters</strong> (<em>int</em><em>, </em><em>optional</em>) -- Number of inner iterations per epoch. Default is 10.</p></li>
<li><p><strong>n_iters</strong> (<em>int</em><em>, </em><em>optional</em>) -- Number of iterations during optimization or epoch. Default is 1000.</p></li>
<li><p><strong>print_inner_itn</strong> (<em>int</em><em>, </em><em>optional</em>) -- Print every <em>n</em> inner iterations. Does not print if 0. Default is 0.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>optional</em>) -- Print every n epoch, or <code class="docutils literal notranslate"><span class="pre">n_iters</span></code>. Does not print if 0. Default is 10.</p></li>
<li><p><strong>simple_verbose</strong> (<em>bool</em><em>, </em><em>optional</em>) -- Turns off details for verbose, such as fit, but instead shows a progress bar.</p></li>
<li><p><strong>stoptime</strong> (<em>float</em><em>, </em><em>optional</em>) -- Number of seconds before early stopping. Default is 1e6.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) -- KKT violations tolerance. Default is 1e-4.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>optional</em>) -- Random seed for initial M.
The default is 42.</p></li>
<li><p><strong>device</strong> (<em>string</em><em>, </em><em>optional</em>) -- Torch device to be used.
'cpu' to use PyTorch with CPU.
'gpu' to use cuda:0
The default is cpu.</p></li>
<li><p><strong>device_num</strong> (<em>string</em><em>, </em><em>optional</em>) -- Which device to to store the tensors.</p></li>
<li><p><strong>return_type</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type for the latent factors.
'torch' keep as torch tensors.
'numpy' convert to numpy arrays.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to be used in torch tensors.
Default is torch.cuda.DoubleTensor.</p></li>
<li><p><strong>follow_M</strong> (<em>bool</em><em>, </em><em>optional</em>) -- Saves M on each iteration.
The default is False.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coords</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Minit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sptensor'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/CP_APR_Torch.html#CP_APR_MU.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU.train" title="Permalink to this definition">#</a></dt>
<dd><p>Factorize the tensor X (i.e. compute the KRUSKAL tensor M).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>PyTorch Sparse Tensor</em><em> or </em><em>dense Numpy array as tensor</em>) -- <p>Original dense or sparse tensor X.</p>
<p>Can be used when Type = 'sptensor'. Then tensor parameter needs to be a PyTorch Sparse tensor.</p>
<p>Or use with Type = 'tensor' and pass the tensor parameter as a dense Numpy array.</p>
<p>Note that PyTorch only supports Type = 'sptensor'.</p>
</p></li>
<li><p><strong>coords</strong> (<em>Numpy array</em><em> (</em><em>i.e. array that is a list</em><em> of </em><em>list</em><em>)</em>) -- <p>Array of non-zero coordinates for sparse tensor X. COO format.</p>
<p>Each entry in this array is a coordinate of a non-zero value in the tensor.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>len(Coords) is number of total entiries in X, and len(coords[0]) should give the number of dimensions.</p>
</p></li>
<li><p><strong>values</strong> (<em>Numpy array</em><em> (</em><em>i.e. list</em><em> of </em><em>non-zero values corresponding to each list</em><em> of </em><em>non-zero coordinates</em><em>)</em>) -- <p>Array of non-zero tensor entries. COO format.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>Length of values must match the length of coords.</p>
</p></li>
<li><p><strong>rank</strong> (<em>int</em>) -- Tensor rank, i.e. number of components to extract.
The default is 2.</p></li>
<li><p><strong>Minit</strong> (<em>string</em><em> or </em><em>dictionary</em><em> of </em><em>latent factors</em>) -- <p>Initial value of latent factors.</p>
<p>If Minit = 'random', initial factors are chosen randomly from uniform distribution between 0 and 1.</p>
<p>Else, pass dictionary where the key is the mode number and value is array size d x r
where d is the number of elements on the dimension and r is the rank.</p>
<p>The default is &quot;random&quot;.</p>
</p></li>
<li><p><strong>Type</strong> (<em>string</em>) -- <p>Type of tensor (i.e. sparse or dense).</p>
<p>Use 'sptensor' for sparse, and 'tensor' for dense tensors.</p>
<p>'sptensor' can be used with method = 'torch', method = 'numpy'.</p>
<p>If 'sptensor' used, pass the list of non-zero coordinates using the Coords parameter
and the corresponding list of non-zero elements with values.</p>
<p>'sptensor' can also be used with the PyTorch Sparse format. Pass the torch.sparse format in the tensor parameter.</p>
<p>'tensor' can be used with method = 'numpy' only. Pass the tensor using tensor parameter in that case.</p>
<p>The default is 'sptensor'.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><strong>result</strong> -- KRUSKAL tensor M is returned.
The latent factors can be found with the key 'Factors'.</p>
<p>The weight of each component can be found with the key 'Weights'.</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-pyCP_APR.torch_backend.ktensor_Torch">
<span id="pycp-apr-torch-backend-ktensor-torch-module"></span><h2>pyCP_APR.torch_backend.ktensor_Torch module<a class="headerlink" href="#module-pyCP_APR.torch_backend.ktensor_Torch" title="Permalink to this heading">#</a></h2>
<p>ktensor_Torch.py contains the K_TENSOR class for KRUSKAL tensor M object representation.</p>
<p class="rubric">References</p>
<p>[1] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.</p>
<p>[2] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, <a class="reference external" href="http://dx.doi.org/10.1145/1186785.1186794">http://dx.doi.org/10.1145/1186785.1186794</a>.</p>
<p>[3] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, <a class="reference external" href="http://dx.doi.org/10.1137/060676489">http://dx.doi.org/10.1137/060676489</a>.</p>
<p>[4] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.</p>
<p>&#64;author: Maksim Ekin Eren</p>
<dl class="py class">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyCP_APR.torch_backend.ktensor_Torch.</span></span><span class="sig-name descname"><span class="pre">K_TENSOR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Rank</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Minit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'torch.DoubleTensor'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/ktensor_Torch.html#K_TENSOR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Initilize the K_TENSOR class.</p>
<p>Creates the object representation of M.</p>
<p>If initial M is not passed, by default, creates M from uniform distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Rank</strong> (<em>int</em>) -- Tensor rank, i.e. number of components in M.</p></li>
<li><p><strong>Size</strong> (<em>list</em>) -- Shape of the tensor.</p></li>
<li><p><strong>Minit</strong> (<em>string</em><em> or </em><em>dictionary</em><em> of </em><em>latent factors</em>) -- <p>Initial value of latent factors.</p>
<p>If Minit = 'random', initial factors are chosen randomly from uniform distribution between 0 and 1.</p>
<p>Else, pass dictionary where the key is the mode number and value is array size d x r
where d is the number of elements on the dimension and r is the rank.</p>
<p>The default is &quot;random&quot;.</p>
</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>optional</em>) -- Random seed for initial M.
The default is 42.</p></li>
<li><p><strong>device</strong> (<em>string</em><em>, </em><em>optional</em>) -- Torch device to be used.
'cpu' to use PyTorch with CPU.
'gpu' to use cuda:0
The default is cpu.</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to be used in torch tensors.
Default is torch.cuda.DoubleTensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR.deep_copy_factors">
<span class="sig-name descname"><span class="pre">deep_copy_factors</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/ktensor_Torch.html#K_TENSOR.deep_copy_factors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR.deep_copy_factors" title="Permalink to this definition">#</a></dt>
<dd><p>Creates a deep copy of the latent factors in M.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>factors</strong> -- Copy of the latent factors of M.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-pyCP_APR.torch_backend.sptensor_Torch">
<span id="pycp-apr-torch-backend-sptensor-torch-module"></span><h2>pyCP_APR.torch_backend.sptensor_Torch module<a class="headerlink" href="#module-pyCP_APR.torch_backend.sptensor_Torch" title="Permalink to this heading">#</a></h2>
<p>sptensor_Torch.py contains the SP_TENSOR class which is the object representation
of the sparse tensor X in COO format.</p>
<p class="rubric">References</p>
<p>[1] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.</p>
<p>[2] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, <a class="reference external" href="http://dx.doi.org/10.1145/1186785.1186794">http://dx.doi.org/10.1145/1186785.1186794</a>.</p>
<p>[3] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, <a class="reference external" href="http://dx.doi.org/10.1137/060676489">http://dx.doi.org/10.1137/060676489</a>.</p>
<p>[4] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.</p>
<p>&#64;author: maksimekineren</p>
<dl class="py class">
<dt class="sig sig-object py" id="pyCP_APR.torch_backend.sptensor_Torch.SP_TENSOR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pyCP_APR.torch_backend.sptensor_Torch.</span></span><span class="sig-name descname"><span class="pre">SP_TENSOR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Coords</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'torch.DoubleTensor'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyCP_APR/torch_backend/sptensor_Torch.html#SP_TENSOR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pyCP_APR.torch_backend.sptensor_Torch.SP_TENSOR" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Initilize the SP_TENSOR class.</p>
<p>Sorts the tensor entries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Tensor</strong> (<em>PyTorch Sparse Tensor</em><em> or </em><em>dense Numpy array as tensor</em>) -- <p>Original dense or sparse tensor X.</p>
<p>Can be used when Type = 'sptensor'. Then Tensor needs to be a PyTorch Sparse tensor.</p>
<p>Or use with Type = 'tensor' and pass Tensor as a dense Numpy array.</p>
<p>Note that PyTorch only supports Type = 'sptensor'.</p>
</p></li>
<li><p><strong>Coords</strong> (<em>Numpy array</em><em> (</em><em>i.e. array that is a list</em><em> of </em><em>list</em><em>)</em>) -- <p>Array of non-zero coordinates for sparse tensor X. COO format.</p>
<p>Each entry in this array is a coordinate of a non-zero value in the tensor.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>len(Coords) is number of total entiries in X, and len(coords[0]) should give the number of dimensions.</p>
</p></li>
<li><p><strong>Values</strong> (<em>Numpy array</em><em> (</em><em>i.e. list</em><em> of </em><em>non-zero values corresponding to each list</em><em> of </em><em>non-zero coordinates</em><em>)</em>) -- <p>Array of non-zero tensor entries. COO format.</p>
<p>Used when Type = 'sptensor' and tensor parameter is not passed.</p>
<p>Length of values must match the length of coords.</p>
</p></li>
<li><p><strong>dtype</strong> (<em>string</em><em>, </em><em>optional</em>) -- Type to be used in torch tensors.
Default is torch.cuda.DoubleTensor.</p></li>
<li><p><strong>device</strong> (<em>string</em><em>, </em><em>optional</em>) -- Torch device to be used.
'cpu' to use PyTorch with CPU.
'gpu' to use cuda:0
The default is cpu.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-pyCP_APR.torch_backend">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pyCP_APR.torch_backend" title="Permalink to this heading">#</a></h2>
<p>2021. Triad National Security, LLC. All rights reserved.
This program was produced under U.S. Government contract 89233218CNA000001 for Los Alamos
National Laboratory (LANL), which is operated by Triad National Security, LLC for the U.S.
Department of Energy/National Nuclear Security Administration. All rights in the program are
reserved by Triad National Security, LLC, and the U.S. Department of Energy/National Nuclear
Security Administration. The Government is granted for itself and others acting on its behalf a
nonexclusive, paid-up, irrevocable worldwide license in this material to reproduce, prepare
derivative works, distribute copies to the public, perform publicly and display publicly, and to permit
others to do so.</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pyCP_APR.numpy_backend.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">pyCP_APR.numpy_backend package</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.CP_APR_Torch">pyCP_APR.torch_backend.CP_APR_Torch module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU"><code class="docutils literal notranslate"><span class="pre">CP_APR_MU</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.CP_APR_Torch.CP_APR_MU.train"><code class="docutils literal notranslate"><span class="pre">CP_APR_MU.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.ktensor_Torch">pyCP_APR.torch_backend.ktensor_Torch module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR"><code class="docutils literal notranslate"><span class="pre">K_TENSOR</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.ktensor_Torch.K_TENSOR.deep_copy_factors"><code class="docutils literal notranslate"><span class="pre">K_TENSOR.deep_copy_factors()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend.sptensor_Torch">pyCP_APR.torch_backend.sptensor_Torch module</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyCP_APR.torch_backend.sptensor_Torch.SP_TENSOR"><code class="docutils literal notranslate"><span class="pre">SP_TENSOR</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-pyCP_APR.torch_backend">Module contents</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Maksim E. Eren, Juston S. Moore, Erik Skau, Manish Bhattarai, Gopinath Chennupati, Boian S. Alexandrov
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2021, LANL.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>