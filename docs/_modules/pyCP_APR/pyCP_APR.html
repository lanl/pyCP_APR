

<!DOCTYPE html>


<html lang="Python" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pyCP_APR.pyCP_APR &#8212; pyCP_APR 1.0.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/pyCP_APR/pyCP_APR';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="Python"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">pyCP_APR 1.0.2 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../CP_APR.html">pyCP_APR.CP_APR API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../datasets.html">pyCP_APR.datasets API</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../modules.html">pyCP_APR Package</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../pyCP_APR.html">pyCP_APR package</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../pyCP_APR.applications.html">pyCP_APR.applications package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pyCP_APR.numpy_backend.html">pyCP_APR.numpy_backend package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pyCP_APR.torch_backend.html">pyCP_APR.torch_backend package</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for pyCP_APR.pyCP_APR</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">pyCP_APR.py is the Scikit-learn like API for interacting with the CP-APR algorithm. The **pyCP_APR.CP_APR** wraps</span>
<span class="sd">both the Numpy and PyTorch backend. **pyCP_APR.CP_APR** also includes API calls for anomaly detection utilities. Sparse tensor entries are scored by calculating p-values over the fitted model, where the lower p-value scores are an indicator for anomaly.\n</span>

<span class="sd">The fitted model (or factorized tensor, i.e. the KRUSKAL tensor M) during the training time describes the normal or the expected behavior which follows the Poisson distribution. We say that the entries of the tensor in the test set are drawn from the same distribution</span>
<span class="sd">as the factorized training tensor M. Using M, we calculate how likely the entries of the test tensor to occur given what was expected. This methodology was introduced by Eren et al. in [1].</span>

<span class="sd">Some code comments are borrowed from the original implementation of CP-APR in [2-5].</span>


<span class="sd">References</span>
<span class="sd">========================================</span>
<span class="sd">[1] M. E. Eren, J. S. Moore and B. S. Alexandrov, &quot;Multi-Dimensional Anomalous Entity Detection via Poisson Tensor Factorization,&quot; 2020 IEEE International Conference on Intelligence and Security Informatics (ISI), 2020, pp. 1-6, doi: 10.1109/ISI49825.2020.9280524.\n</span>
<span class="sd">[2] General software, latest release: Brett W. Bader, Tamara G. Kolda and others, Tensor Toolbox for MATLAB, Version 3.2.1, www.tensortoolbox.org, April 5, 2021.\n</span>
<span class="sd">[3] Dense tensors: B. W. Bader and T. G. Kolda, Algorithm 862: MATLAB Tensor Classes for Fast Algorithm Prototyping, ACM Trans. Mathematical Software, 32(4):635-653, 2006, http://dx.doi.org/10.1145/1186785.1186794.\n</span>
<span class="sd">[4] Sparse, Kruskal, and Tucker tensors: B. W. Bader and T. G. Kolda, Efficient MATLAB Computations with Sparse and Factored Tensors, SIAM J. Scientific Computing, 30(1):205-231, 2007, http://dx.doi.org/10.1137/060676489.\n</span>
<span class="sd">[5] Chi, E.C. and Kolda, T.G., 2012. On tensors, sparsity, and nonnegative factorizations. SIAM Journal on Matrix Analysis and Applications, 33(4), pp.1272-1299.\n</span>

<span class="sd">@author Maksim Ekin Eren</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.torch_backend.CP_APR_Torch</span> <span class="kn">import</span> <span class="n">CP_APR_MU</span> <span class="k">as</span> <span class="n">CP_APR_MU_tr</span>
<span class="kn">from</span> <span class="nn">.numpy_backend.CP_APR</span> <span class="kn">import</span> <span class="n">CP_APR_MU</span>

<span class="kn">from</span> <span class="nn">.applications.tensor_anomaly_detection</span> <span class="kn">import</span> <span class="n">PoissonTensorAnomaly</span>
<span class="kn">from</span> <span class="nn">.applications.tensor_anomaly_detection_v2</span> <span class="kn">import</span> <span class="n">PoissonTensorAnomaly_v2</span> <span class="k">as</span> <span class="n">PTA</span>

<div class="viewcode-block" id="CP_APR"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR">[docs]</a><span class="k">class</span> <span class="nc">CP_APR</span><span class="p">():</span>


    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initilize the **pyCP_APR.CP_APR** class. **pyCP_APR.CP_APR** class is the wrapper for the CP-APR algorithm&#39;s Python implementation with</span>
<span class="sd">        both *Numpy* and *PyTorch* backend.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        method : string, optional</span>
<span class="sd">            Specifies which backend to use when running CP-APR, and sets the model (i.e. **pyCP_APR.CP_APR.model**)</span>
<span class="sd">            accordingly.\n</span>
<span class="sd">            ``method=&#39;torch&#39;`` or ``method=&#39;pytorch&#39;`` will use PyTorch and enable GPU utilization.\n</span>
<span class="sd">            ``method=&#39;numpy&#39;`` will use Numpy backend.\n</span>
<span class="sd">            Default is ``method=&#39;torch&#39;``.</span>
<span class="sd">            </span>
<span class="sd">            .. warning::</span>
<span class="sd">            </span>
<span class="sd">                * ``method=&#39;torch&#39;`` or ``method=&#39;pytorch&#39;`` only supports sparse tensors in COO format.</span>
<span class="sd">                * ``method=&#39;numpy&#39;`` supports both sparse (COO format) &amp; dense tensors.</span>
<span class="sd">            </span>
<span class="sd">        epsilon : float, optional</span>
<span class="sd">            Prevents zero division. Default is 1e-10.</span>
<span class="sd">        kappa : float, optional</span>
<span class="sd">            Fix slackness level. Default is 1e-2.</span>
<span class="sd">        kappa_tol : float, optional</span>
<span class="sd">            Tolerance on slackness level. Default is 1e-10.</span>
<span class="sd">        max_inner_iters : int, optional</span>
<span class="sd">            Number of inner iterations per epoch. Default is 10.</span>
<span class="sd">        follow_M : bool, optional</span>
<span class="sd">            Saves M on each iteration if ``True``.</span>
<span class="sd">            The default is False.</span>
<span class="sd">        n_iters : int, optional</span>
<span class="sd">            Number of iterations during optimization or epoch. Default is 1000.</span>
<span class="sd">        print_inner_itn : int, optional</span>
<span class="sd">            Print every *n* inner iterations. Does not print if 0. Default is 0.</span>
<span class="sd">        verbose : int, optional</span>
<span class="sd">            Print every n epoch, or ``n_iters``. Does not print if 0. Default is 10.</span>
<span class="sd">        stoptime : float, optional</span>
<span class="sd">            Number of seconds before early stopping. Default is 1e6.</span>
<span class="sd">        tol : float, optional</span>
<span class="sd">             KKT violations tolerance. Default is 1e-4.</span>
<span class="sd">        random_state : int, optional</span>
<span class="sd">            Random seed for the initial M (KRUSKAL Tensor). Default is 42.</span>
<span class="sd">        device : string, optional</span>
<span class="sd">            Specifies CPU or GPU utilization for factorizing the tensor.\n</span>
<span class="sd">            ``device=&#39;cpu&#39;`` to use PyTorch with CPU.\n</span>
<span class="sd">            ``device=&#39;gpu&#39;`` to use PyTorch with GPU. Only if a CUDA device is available.\n</span>
<span class="sd">            Default is ``device=&#39;cpu&#39;``.</span>
<span class="sd">            </span>
<span class="sd">            .. warning::</span>
<span class="sd">            </span>
<span class="sd">                Only used when ``method=&#39;torch&#39;`` or ``method=&#39;pytorch&#39;``.</span>
<span class="sd">                </span>
<span class="sd">        device_num : int or string, optional</span>
<span class="sd">            Which GPU to use to compute the KRUSKAL tensor M.\n</span>
<span class="sd">            Default is ``device_num=0``.</span>
<span class="sd">            </span>
<span class="sd">            .. warning::</span>
<span class="sd">                </span>
<span class="sd">                 Only used when ``method=&#39;torch&#39;`` and ``device=&#39;gpu&#39;``.</span>

<span class="sd">        return_type : string, optional</span>
<span class="sd">            The return type for the final KRUSKAL tensor M.\n</span>
<span class="sd">            ``return_type=&#39;torch&#39;`` keep as torch tensors.\n</span>
<span class="sd">            ``return_type=&#39;numpy&#39;`` convert to Numpy arrays and transfer the tensor back to CPU if GPU was used.\n</span>
<span class="sd">            Default is ``return_type=&#39;numpy&#39;``.</span>
<span class="sd">            </span>
<span class="sd">            .. warning::</span>
<span class="sd">            </span>
<span class="sd">                 Only used when ``method=&#39;torch&#39;`` or ``method=&#39;pytorch&#39;``.</span>
<span class="sd">            </span>
<span class="sd">        dtype : string, optional</span>
<span class="sd">            Type to be used in torch tensors.\n</span>
<span class="sd">            Default is **&#39;torch.DoubleTensor&#39;** when ``device=&#39;cpu&#39;``. Default is **&#39;torch.cuda.DoubleTensor&#39;** when ``device=&#39;gpu&#39;``.\n</span>
<span class="sd">            </span>
<span class="sd">            .. warning::</span>
<span class="sd">            </span>
<span class="sd">                Used only when ``method=&#39;torch&#39;`` or ``method=&#39;pytorch&#39;``.</span>
<span class="sd">        </span>
<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            **Example**</span>

<span class="sd">            Using the *PyTorch* backend on GPU 0:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from pyCP_APR.pyCP_APR import CP_APR</span>

<span class="sd">                # CP-APR Object with PyTorch backend on a GPU. Transfer the latent factors back to Numpy arrays.</span>
<span class="sd">                cp_apr = CP_APR(n_iters=10, random_state=42, verbose=1, device=&#39;gpu&#39;, device_num=0, return_type=&#39;numpy&#39;)</span>


<span class="sd">            Using the *Numpy* backend:</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                cp_apr = CP_APR(n_iters=10, random_state=42, verbose=1, method=&#39;numpy&#39;)</span>


<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Compute method</span>
        <span class="k">if</span> <span class="s1">&#39;method&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;torch&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span>

            <span class="n">allowed_methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;torch&#39;</span><span class="p">,</span> <span class="s1">&#39;pytorch&#39;</span><span class="p">,</span> <span class="s1">&#39;numpy&#39;</span><span class="p">]</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">in</span> <span class="n">allowed_methods</span><span class="p">,</span> <span class="s2">&quot;Unknown method. Please choose from: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">allowed_methods</span><span class="p">))</span>

        <span class="c1"># CP-APR PyTorch</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;torch&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;pytorch&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CP_APR_MU_tr</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span>
        <span class="c1"># CP-APR Numpy</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;numpy&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">CP_APR_MU</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span>

        <span class="c1"># Save the results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PTA</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="CP_APR.get_params"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.get_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The function call that returns the *model* parameters in a dictionary where a key is the *model* variable name</span>
<span class="sd">        and the value is its current value. *model* is the backend used during factorization (i.e. **pyCP_APR.torch_cp.CP_APR_Torch** or </span>
<span class="sd">        **pyCP_APR.numpy_cp.CP_APR**).\n</span>


<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            Model parameters can also be accessed with a call directly to the *model* (i.e. **pyCP_APR.CP_APR.model**).</span>

<span class="sd">        </span>
<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            **Example**</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                from pyCP_APR import CP_APR</span>
<span class="sd">                cp_apr = CP_APR(n_iters=10)</span>
<span class="sd">                cp_apr.get_params()</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                {</span>
<span class="sd">                 &#39;verbose&#39;: 10,</span>
<span class="sd">                 &#39;print_inner_itn&#39;: 0,</span>
<span class="sd">                 &#39;start_time&#39;: -1,</span>
<span class="sd">                 &#39;final_iter&#39;: -1,</span>
<span class="sd">                 &#39;dtype&#39;: &#39;torch.DoubleTensor&#39;,</span>
<span class="sd">                 &#39;device&#39;: &#39;cpu&#39;,</span>
<span class="sd">                 &#39;device_num&#39;: &#39;0&#39;,</span>
<span class="sd">                 &#39;return_type&#39;: &#39;numpy&#39;,</span>
<span class="sd">                 &#39;X&#39;: None,</span>
<span class="sd">                 &#39;M&#39;: None,</span>
<span class="sd">                 &#39;tol&#39;: 0.0001,</span>
<span class="sd">                 &#39;stoptime&#39;: 1000000.0,</span>
<span class="sd">                 &#39;exec_time&#39;: -1,</span>
<span class="sd">                 &#39;n_iters&#39;: 10,</span>
<span class="sd">                 &#39;max_inner_iters&#39;: 10,</span>
<span class="sd">                 &#39;random_state&#39;: 42,</span>
<span class="sd">                 &#39;kappa&#39;: 0.01,</span>
<span class="sd">                 &#39;kappa_tol&#39;: 1e-10,</span>
<span class="sd">                 &#39;kktViolations&#39;: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]),</span>
<span class="sd">                 &#39;nInnerIters&#39;: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),</span>
<span class="sd">                 &#39;times&#39;: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),</span>
<span class="sd">                 &#39;logLikelihoods&#39;: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),</span>
<span class="sd">                 &#39;epsilon&#39;: tensor(1.0000e-10),</span>
<span class="sd">                 &#39;obj&#39;: 0</span>
<span class="sd">                 }</span>


<span class="sd">            The model parameters of a fitted model may look like following:</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                {</span>
<span class="sd">                 &#39;verbose&#39;: 1,</span>
<span class="sd">                 &#39;print_inner_itn&#39;: 0,</span>
<span class="sd">                 &#39;start_time&#39;: 1621842138.9178197,</span>
<span class="sd">                 &#39;final_iter&#39;: 10,</span>
<span class="sd">                 &#39;dtype&#39;: &#39;torch.cuda.DoubleTensor&#39;,</span>
<span class="sd">                 &#39;device&#39;: device(type=&#39;cuda&#39;, index=0),</span>
<span class="sd">                 &#39;device_num&#39;: &#39;0&#39;,</span>
<span class="sd">                 &#39;return_type&#39;: &#39;numpy&#39;,</span>
<span class="sd">                 &#39;X&#39;: &lt;pyCP_APR.torch_cp.sptensor_Torch.SP_TENSOR at 0x7f759dde0eb0&gt;,</span>
<span class="sd">                 &#39;M&#39;: &lt;pyCP_APR.torch_cp.ktensor_Torch.K_TENSOR at 0x7f759dde0c40&gt;,</span>
<span class="sd">                 &#39;tol&#39;: 0.0001,</span>
<span class="sd">                 &#39;stoptime&#39;: 1000000.0,</span>
<span class="sd">                 &#39;exec_time&#39;: 0.41489696502685547,</span>
<span class="sd">                 &#39;n_iters&#39;: 10,</span>
<span class="sd">                 &#39;max_inner_iters&#39;: 10,</span>
<span class="sd">                 &#39;random_state&#39;: 42,</span>
<span class="sd">                 &#39;kappa&#39;: 0.01,</span>
<span class="sd">                 &#39;kappa_tol&#39;: 1e-10,</span>
<span class="sd">                 &#39;kktViolations&#39;: array([  0.90469806, 170.76687748, 439.2454979 , 171.40815408,</span>
<span class="sd">                         32.90351131,  49.3060232 , 112.32568973, 156.01606934,</span>
<span class="sd">                         30.25656979,  24.61207396]),</span>
<span class="sd">                 &#39;nInnerIters&#39;: array([38., 34., 34., 33., 33., 33., 33., 33., 33., 33.]),</span>
<span class="sd">                 &#39;times&#39;: array([0.05231047, 0.09365845, 0.14037013, 0.18132734, 0.22193289,</span>
<span class="sd">                        0.26159644, 0.29836512, 0.33511233, 0.37501359, 0.41115212]),</span>
<span class="sd">                 &#39;logLikelihoods&#39;: array([9.59298322e+12, 1.02443325e+13, 1.03623011e+13, 1.04159710e+13,</span>
<span class="sd">                        1.04551136e+13, 1.04828857e+13, 1.05091620e+13, 1.05297763e+13,</span>
<span class="sd">                        1.05492323e+13, 1.05635448e+13]),</span>
<span class="sd">                 &#39;epsilon&#39;: array(1.e-10),</span>
<span class="sd">                 &#39;obj&#39;: 10563544752580.432</span>
<span class="sd">                 }</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span></div>

<div class="viewcode-block" id="CP_APR.get_score"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.get_score">[docs]</a>    <span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The function call that returns the objective value of the model.\n</span>
<span class="sd">        Model is **pyCP_APR.CP_APR.model.obj**.\n</span>
<span class="sd">        If an ensemble of tensors is trained (see **pyCP_APR.CP_APR.fit()**), a list of scores is provided instead.\n</span>
<span class="sd">        Note that the model has to be already fit.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            Model fit score.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Fit the tensor to aquire the latent factors first.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">score</span></div>

<div class="viewcode-block" id="CP_APR.get_prediction"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.get_prediction">[docs]</a>    <span class="k">def</span> <span class="nf">get_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The function call that returns the predictions.\n</span>
<span class="sd">        The model must be already fitted using **pyCP_APR.CP_APR.fit()**,</span>
<span class="sd">        and links must be already predicted using **pyCP_APR.CP_APR.predict_scores()**.\n</span>
<span class="sd">        </span>
<span class="sd">        .. warning::</span>
<span class="sd">        </span>
<span class="sd">            The prediction is returned as dictionary with the keys &#39;objective&#39; and &#39;lambda&#39;.\n</span>
<span class="sd">            The &#39;objective&#39; key depends on the ``objective`` parameter used when predicting the scores in **pyCP_APR.CP_APR.predict_scores()**.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        predictions : dict</span>
<span class="sd">            The prediction contents are based on the objective parameter used during **pyCP_APR.CP_APR.predict_scores()**.\n</span>
<span class="sd">            If ``objective=&#39;p_value&#39;``, returns ``{&#39;p_value&#39;: array, &#39;lambda&#39;: array}``.\n</span>
<span class="sd">            If ``objective=&#39;log_likelihood&#39;``, returns ``{&#39;log_likelihood&#39;: array, &#39;lambda&#39;: array}``.</span>

<span class="sd">        </span>
<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            **Example**</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                cp_apr.get_prediction()</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                {</span>
<span class="sd">                 &#39;p_value&#39;: array([1., 1., 1., ..., 1., 1., 1.]),</span>
<span class="sd">                 &#39;lambda&#39;: array([ 3796.43165171,  2315.69440274,  1001.22377495, ..., 290.35037293,  2952.72557334, 30309.82134089])</span>
<span class="sd">                }</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Perform the predictions over the latent factors first.&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span></div>

<div class="viewcode-block" id="CP_APR.set_params"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.set_params">[docs]</a>    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the model parameters.\n</span>
<span class="sd">        Here the model is **pyCP_APR.CP_APR.model**.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        parameters : dict</span>
<span class="sd">            All model parameters. See **pyCP_APR.CP_APR** class initilization parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            self is returned.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">parameter</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">parameter</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="CP_APR.predict_probas"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.predict_probas">[docs]</a>    <span class="k">def</span> <span class="nf">predict_probas</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis_map</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the probabilities of the test tensor entries.\n</span>
<span class="sd">        Then returns the prediction scores with ROC-AUC and PR-AUC metrics.\n</span>
<span class="sd">        Fusion is performed on the dimensions indicated by ``axis_map``.</span>
<span class="sd">        Dimension fusion uses the Harmonic Mean.\n</span>
<span class="sd">        **This function is in beta stage.**</span>

<span class="sd">        </span>
<span class="sd">        .. note::</span>
<span class="sd">            Anomaly detection can be performed either using **predict_scores()**, or using **transform()** and **predict_probas()**. </span>
<span class="sd">            While using **transform()** and **predict_probas()** yields faster computation time and more established dimension fusion results, **predict_scores()** provides wider range of features for anomaly detection.</span>


<span class="sd">        .. warning:: </span>
<span class="sd">            In order to use the **predict_probas()** function, below has to be done first:</span>

<span class="sd">            1. Tensor has to be factorized using **fit()** function first to extract the KRUSKAL tensor M.</span>
<span class="sd">            2. After **fit()**, Poisson lambda values for the test tensor has to be calculated using the **transform()** function.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : list or array</span>
<span class="sd">            Labels for each entry in the sparse test tensor.</span>
<span class="sd">        axis_map : OrderedDict, optional</span>
<span class="sd">            If fusing dimensions, list of dimension numbers can be passed as *OrderedDict* to identify which dimensions to fuse.\n</span>
<span class="sd">            The tuples in the ordered dictionary map will have 2 entries, where the first entry is the dimension name in string, and the</span>
<span class="sd">            second entry is the dimension number(s) in list.</span>
<span class="sd">            The default is ``axis_map=None``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prediction scores : dict or Pandas DataFrame</span>
<span class="sd">            If not fusing the dimensions over the transformed tensor, returns a dictionary with prediction scores.\n</span>
<span class="sd">            ``{&quot;roc_auc&quot;:float, &quot;pr_auc&quot;:float}``\n</span>
<span class="sd">            If dimensions are being fused using the ``axis_map`` parameter, returns a *Pandas DataFrame* with the prediction</span>
<span class="sd">            scores. The columns for the returned DataFrame in this case are &#39;fusion&#39;, &#39;method&#39;, &#39;metric&#39;, and &#39;score&#39;.\n</span>
<span class="sd">            </span>
<span class="sd">            .. note::</span>
<span class="sd">            </span>
<span class="sd">                For a four dimensional tensor with dimension names *U x S x D x s*, ``axis_map`` to fuse to first dimension, and first and second </span>
<span class="sd">                dimensions would be: ``axis_map=OrderedDict(((&#39;U&#39;, [0]), (&#39;US&#39;, [0, 1])))``. Here ``&#39;U&#39;`` and ``&#39;US&#39;`` are the dimension names,</span>
<span class="sd">                and ``[0]`` and ``[0,1]`` are the dimension numbers respectively.\n</span>
<span class="sd">                Another example is illustrated below.</span>

<span class="sd">            </span>
<span class="sd">                .. code-block:: python</span>

<span class="sd">                    from collections import OrderedDict</span>
<span class="sd">                    axis_map = OrderedDict(((&#39;U&#39;, [0]), (&#39;S&#39;, [1]), (&#39;D&#39;, [2]), (&#39;US&#39;, [0, 1]), (&#39;UD&#39;, [0, 2]), (&#39;SD&#39;, [1, 2])))</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Fit the tensor to aquire the latent factors first.&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">PTA</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Transform the indicies in the latent factors first.&quot;</span>
        <span class="k">if</span> <span class="n">axis_map</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">PTA</span><span class="o">.</span><span class="n">get_dimension_fusion_scores</span><span class="p">(</span><span class="n">axis_map</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">PTA</span><span class="o">.</span><span class="n">get_link_prediction_scores</span><span class="p">(</span><span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="CP_APR.transform"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indicies</span><span class="p">,</span> <span class="n">ensemble_significance</span> <span class="o">=</span> <span class="p">[]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given the sparse test tensor entries (or indicies, i.e. coordinates of non-zero values), calculate the Poisson lambda values.\n</span>
<span class="sd">        The Poission lambda value can be used to identify how likely was that coordinate in the test tensor to occur given</span>
<span class="sd">        what we have learned during the training time.\n</span>
<span class="sd">        </span>
<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            * If 2 tensors are weighted during the calculation of lambdas, the weight of each can be specified using ``ensemble_significance``. See **pyCP_APR.CP_APR.fit()** for factorazing ensemble of tensor ranks. For instance, if ``ensemble_significance=[0.1, 0.9]``, ``lambda = (0.1 x lambda_1) + (0.9 x lambda_2)``.</span>
<span class="sd">            * Anomaly detection can be performed either using **predict_scores()**, or using **transform()** and **predict_probas()**. While using **transform()** and **predict_probas()** yields faster computation time and more established dimension fusion results, **predict_scores()** provides wider range of features for anomaly detection.</span>
<span class="sd">        </span>
<span class="sd">        .. warning:: </span>
<span class="sd">            To use the **transform()** function, the model has to be **fit()** first.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        indicies : list or array</span>
<span class="sd">            List of non-zero coordinates in the test tensor.</span>
<span class="sd">        ensemble_significance : list, optional</span>
<span class="sd">            The weight of each tensor during lambda calculations.\n</span>
<span class="sd">            Ensemble significance is automatically applied if multiple tensors are fitted.\n</span>
<span class="sd">            If multiple tensors are fitted, the default is ``ensemble_significance=[0.1, 0.9]``.\n</span>
<span class="sd">            If single tensor is fitted, the default is ``ensemble_significance=[1]``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lambdas : array</span>
<span class="sd">            List of lambda values for each of the non-zero coordinates.</span>
<span class="sd">        </span>
<span class="sd">        </span>
<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            **Example**</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                from pyCP_APR.datasets import load_dataset</span>
<span class="sd">                from pyCP_APR import CP_APR</span>
<span class="sd">                from collections import OrderedDict</span>
<span class="sd">                import numpy as np</span>

<span class="sd">                data = load_dataset(name = &quot;TOY&quot;)</span>

<span class="sd">                # Training set</span>
<span class="sd">                coords_train = data[&#39;train_coords&#39;]</span>
<span class="sd">                nnz_train = data[&#39;train_count&#39;]</span>

<span class="sd">                # Test set</span>
<span class="sd">                coords_test = data[&#39;test_coords&#39;]</span>
<span class="sd">                nnz_test = data[&#39;test_count&#39;]</span>

<span class="sd">                # CP-APR model</span>
<span class="sd">                cp_apr = CP_APR(n_iters=10, random_state=42, verbose=1, method=&#39;numpy&#39;)</span>

<span class="sd">                # factorize X for ranks 1 and 4</span>
<span class="sd">                M = cp_apr.fit(coords=coords_train, values=nnz_train, rank=[1,4])</span>

<span class="sd">                # get the lambdas</span>
<span class="sd">                # returned lambdas are weighted values for rank 1 and rank 4 tensor decomposition Ms</span>
<span class="sd">                lambdas = cp_apr.transform(coords_test)</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Fit the tensor to aquire the latent factors first.&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ensemble_significance</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
                <span class="n">ensemble_significance</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ensemble_significance</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">PTA</span> <span class="o">=</span> <span class="n">PTA</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">indicies</span><span class="p">,</span> <span class="n">ensemble_significance</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">PTA</span><span class="o">.</span><span class="n">get_lambdas</span><span class="p">()</span></div>

<div class="viewcode-block" id="CP_APR.fit"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Takes the decomposition of sparse or dense tensor X and returns the KRUSKAL tensor M.\n</span>
<span class="sd">        Here M is  latent factors and the weight of each R (rank) component.\n</span>
<span class="sd">        If a list of ranks is passed, factorize the tensor for each 2 of the ranks.\n</span>
<span class="sd">        The factorized 2 tensors M in this case will follow the weighted lambda calculations during prediction.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : PyTorch.sparse or Numpy array</span>
<span class="sd">            Original dense or sparse tensor X.\n</span>
<span class="sd">            Can be used when ``Type=&#39;sptensor&#39;``. In this case, ``Tensor`` needs to be a *PyTorch Sparse* tensor format.\n</span>
<span class="sd">            Or use with ``Type=&#39;tensor&#39;`` and pass ``Tensor`` as a dense Numpy array.</span>

<span class="sd">            .. warning::</span>

<span class="sd">                Note that PyTorch backend only supports ``Type=&#39;sptensor&#39;``.</span>

<span class="sd">        coords : Numpy array</span>
<span class="sd">            Array of non-zero coordinates for sparse tensor X. COO format.\n</span>
<span class="sd">            Each entry in this array is a coordinate of a non-zero value in the original tensor X.</span>

<span class="sd">            .. warning::</span>
<span class="sd">            </span>
<span class="sd">                * Used when ``Type=&#39;sptensor&#39;``, and when ``tensor`` parameter is not passed.</span>
<span class="sd">                * ``len(coords)`` is number of total entiries in X, and ``len(coords[0])`` should give the number of dimensions X has.</span>

<span class="sd">        values : Numpy array</span>
<span class="sd">            List of non-zero values corresponding to each list of non-zero coordinates (``coords``).</span>
<span class="sd">            Array of non-zero tensor entries. COO format.</span>

<span class="sd">            .. warning::</span>

<span class="sd">                * Used when ``Type=&#39;sptensor&#39;`` and ``tensor`` parameter is not passed.</span>
<span class="sd">                * Length of ``values`` must match the length of ``coords``.</span>

<span class="sd">        rank : int or list</span>
<span class="sd">            Tensor rank, or list of ranks for two tensors.\n</span>
<span class="sd">            Tensor rank determines the number of components.\n</span>
<span class="sd">            List of ranks will allow using weighted prediction between the two latent factors in KRUSKAL tensor M.\n</span>
<span class="sd">            Pass a single integer or list of length two.\n</span>
<span class="sd">            The default is ``rank=2``.</span>
<span class="sd">        Minit : string or dictionary of latent factors</span>
<span class="sd">            Initial value of latent factors.\n</span>
<span class="sd">            If ``Minit=&#39;random&#39;``, initial factors are drawn randomly from uniform distribution between 0 and 1.\n</span>
<span class="sd">            Else, pass a dictionary where the key is the mode number and value is array size ``d x r``</span>
<span class="sd">            where ``d`` is the number of elements on the dimension and ``r`` is the rank.\n</span>
<span class="sd">            The default is ``Minit=&#39;random&#39;``.</span>
<span class="sd">            </span>
<span class="sd">            .. note::</span>
<span class="sd">            </span>
<span class="sd">                Example on creating initial M for 3 dimensional tensor shaped *5x5x5* for rank 4 decomposition:</span>

<span class="sd">                .. code-block:: python</span>

<span class="sd">                    import numpy as np</span>

<span class="sd">                    num_dimensions = 3</span>
<span class="sd">                    tensor_shape = [5,5,5]</span>
<span class="sd">                    rank = 4</span>
<span class="sd">                    M_init = {&quot;Factors&quot;:{}, &quot;Weights&quot;:[1,1,1]}</span>
<span class="sd">                    for d in range(num_dimensions):</span>
<span class="sd">                            M_init[&quot;Factors&quot;][str(d)] = np.random.uniform(low=0, high=1, size=(tensor_shape[d], rank))</span>
<span class="sd">                    M_init[&quot;Factors&quot;]</span>
<span class="sd">                    </span>
<span class="sd">                .. code-block:: console</span>
<span class="sd">                </span>
<span class="sd">                    {</span>
<span class="sd">                     &#39;0&#39;: array([[0.821161  , 0.419537  , 0.62692165, 0.06294969],</span>
<span class="sd">                            [0.02032657, 0.88625546, 0.74128504, 0.71855629],</span>
<span class="sd">                            [0.70760879, 0.83813636, 0.35128158, 0.94442011],</span>
<span class="sd">                            [0.35780608, 0.83703369, 0.84602297, 0.93760842],</span>
<span class="sd">                            [0.00746915, 0.05974905, 0.49097518, 0.60615737]]),</span>
<span class="sd">                     &#39;1&#39;: array([[0.61902526, 0.78453503, 0.05596952, 0.69149084],</span>
<span class="sd">                            [0.56300552, 0.82418509, 0.04278352, 0.25716303],</span>
<span class="sd">                            [0.66221183, 0.13888761, 0.92502242, 0.57817265],</span>
<span class="sd">                            [0.31738958, 0.87061048, 0.64170398, 0.62236073],</span>
<span class="sd">                            [0.9110603 , 0.5133135 , 0.89232955, 0.09881775]]),</span>
<span class="sd">                     &#39;2&#39;: array([[0.0580065 , 0.82367217, 0.07616138, 0.93873983],</span>
<span class="sd">                            [0.89247679, 0.41388867, 0.82089524, 0.10293565],</span>
<span class="sd">                            [0.13540868, 0.09809637, 0.10844113, 0.90405324],</span>
<span class="sd">                            [0.91167498, 0.67068632, 0.51705956, 0.82211517],</span>
<span class="sd">                            [0.80942828, 0.08450466, 0.6306868 , 0.78132797]])</span>
<span class="sd">                    }</span>

<span class="sd">        Type : string</span>
<span class="sd">            Type of tensor (i.e. sparse or dense).\n</span>
<span class="sd">            Use ``Type=&#39;sptensor&#39;`` for sparse, and ``Type=&#39;tensor&#39;`` for dense tensors.\n</span>
<span class="sd">            &#39;sptensor&#39; can be used with ``method=&#39;torch&#39;``, and ``method=&#39;numpy&#39;``.\n</span>
<span class="sd">            If &#39;sptensor&#39; used, pass the list of non-zero coordinates using the ``coords`` parameter</span>
<span class="sd">            and the corresponding list of non-zero elements with ``values`` parameter. This is the COO representation of X.\n</span>
<span class="sd">            &#39;sptensor&#39; can also be used with the *PyTorch Sparse* format. </span>
<span class="sd">            In that case, pass the tensor X that is in *torch.sparse* format using the ``tensor`` parameter.\n</span>
<span class="sd">            &#39;tensor&#39; can be used with ``method=&#39;numpy&#39;``. In this case, pass the tensor X using the ``tensor`` parameter.\n</span>
<span class="sd">            The default is ``Type=&#39;sptensor&#39;``.</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        KRUSKAL tensor M : dict</span>
<span class="sd">            KRUSKAL tensor M is returned in dict format.\n</span>
<span class="sd">            The latent factors can be found with the key &#39;Factors&#39;.\n</span>
<span class="sd">            The weight of each component can be found with the key &#39;Weights&#39;.</span>


<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            **Example**</span>

<span class="sd">            Sparse tensor X in COO format decomposed using a GPU in the below example:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from pyCP_APR.datasets import load_dataset</span>
<span class="sd">                from pyCP_APR import CP_APR</span>
<span class="sd">                from collections import OrderedDict</span>
<span class="sd">                import numpy as np</span>

<span class="sd">                data = load_dataset(name = &quot;TOY&quot;)</span>

<span class="sd">                # Training set</span>
<span class="sd">                coords_train = data[&#39;train_coords&#39;]</span>
<span class="sd">                nnz_train = data[&#39;train_count&#39;]</span>

<span class="sd">                # Test set</span>
<span class="sd">                coords_test = data[&#39;test_coords&#39;]</span>
<span class="sd">                nnz_test = data[&#39;test_count&#39;]</span>

<span class="sd">                # CP-APR model</span>
<span class="sd">                cp_apr = CP_APR(n_iters=10, random_state=42, verbose=1, </span>
<span class="sd">                    method=&#39;torch&#39;,</span>
<span class="sd">                    device=&#39;gpu&#39;, </span>
<span class="sd">                    device_num=0</span>
<span class="sd">                   )</span>

<span class="sd">                # factorize the tensor for ranks 1 and 4</span>
<span class="sd">                M = cp_apr.fit(coords=coords_train, values=nnz_train, rank=[1,4])</span>


<span class="sd">            Above example takes the tensor decomposition of X for ranks 1 and 4. Below is an example showing a single rank decomposition:</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                M = cp_apr.fit(coords=coords_train, values=nnz_train, rank=4)</span>


<span class="sd">            An example of factorized X, i.e. M (KRUSKAL tensor). Below example M is rank 2, and has 3 dimensions:</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                {</span>
<span class="sd">                   &#39;Factors&#39;: </span>
<span class="sd">                   {</span>
<span class="sd">                      &#39;0&#39;: </span>
<span class="sd">                         array([[5.88838457e-51, 2.13058370e-01],</span>
<span class="sd">                         [3.23364716e-04, 1.34610100e-01],</span>
<span class="sd">                         [2.05013230e-01, 7.12928005e-37],</span>
<span class="sd">                         [1.48424405e-01, 0.00000000e+00],</span>
<span class="sd">                         [9.76200219e-02, 1.48477484e-01],</span>
<span class="sd">                         [2.51566211e-02, 2.06908903e-01],</span>
<span class="sd">                         [1.43573934e-01, 3.34319439e-88],</span>
<span class="sd">                         [2.61925420e-01, 4.76257924e-33],</span>
<span class="sd">                         [9.37106506e-02, 1.87295857e-01],</span>
<span class="sd">                         [2.42523537e-02, 1.09649287e-01]]),</span>
<span class="sd">                      &#39;1&#39;: </span>
<span class="sd">                         array([[2.31775360e-241, 5.03672967e-002],</span>
<span class="sd">                         [7.79309622e-002, 1.00144467e-137],</span>
<span class="sd">                         [0.00000000e+000, 7.84481789e-002],</span>
<span class="sd">                         [1.23105143e-001, 9.77480876e-002],</span>
<span class="sd">                         [3.30736653e-002, 5.64828345e-002],</span>
<span class="sd">                         [1.56285154e-078, 9.36029407e-003],</span>
<span class="sd">                         [4.85047483e-002, 0.00000000e+000],</span>
<span class="sd">                         [3.10430389e-002, 0.00000000e+000],</span>
<span class="sd">                         [2.39290092e-002, 3.29838934e-002],</span>
<span class="sd">                         [0.00000000e+000, 0.00000000e+000],</span>
<span class="sd">                         [6.75832826e-002, 0.00000000e+000]]),</span>
<span class="sd">                      &#39;2&#39;: </span>
<span class="sd">                         array([[2.71626813e-002, 0.00000000e+000],</span>
<span class="sd">                         [1.68530286e-003, 4.18040234e-002],</span>
<span class="sd">                         [0.00000000e+000, 2.00577503e-002],</span>
<span class="sd">                         [0.00000000e+000, 5.34873341e-002],</span>
<span class="sd">                         [0.00000000e+000, 2.89723060e-002],</span>
<span class="sd">                         [4.00972915e-002, 4.85187813e-161],</span>
<span class="sd">                         [4.49477703e-002, 0.00000000e+000],</span>
<span class="sd">                         [1.00243229e-002, 0.00000000e+000],</span>
<span class="sd">                         [0.00000000e+000, 3.69954061e-002],</span>
<span class="sd">                         [2.29589330e-002, 1.33718335e-002],</span>
<span class="sd">                         [3.23365254e-002, 0.00000000e+000]])},</span>
<span class="sd">                  &#39;Weights&#39;: array([3092.47820339, 2243.52179661])</span>
<span class="sd">                }</span>


<span class="sd">            Below is an example of how *torch.sparse* format can be used as the tensor X:</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                import torch</span>

<span class="sd">                i = torch.LongTensor([[0, 1, 1], [2, 0, 2], [2, 0, 1]])</span>

<span class="sd">                v = torch.FloatTensor([3, 4, 5])</span>
<span class="sd">                X = torch.sparse.FloatTensor(i, v, torch.Size([4,4,4]))</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                from pyCP_APR import CP_APR</span>

<span class="sd">                cp_apr = CP_APR(n_iters=100, verbose=10, device=&#39;gpu&#39;)</span>
<span class="sd">                result = cp_apr.fit(tensor=X, rank=30)</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                Using TITAN RTX</span>
<span class="sd">                CP-APR (MU):</span>
<span class="sd">                Iter=1, Inner Iter=30, KKT Violation=0.425532, obj=4.887921, nViolations=0</span>
<span class="sd">                Exiting because all subproblems reached KKT tol.</span>
<span class="sd">                ===========================================</span>
<span class="sd">                 Final log-likelihood = 4.888204</span>
<span class="sd">                 Final least squares fit = 0.999995</span>
<span class="sd">                 Final KKT violation = 0.000007</span>
<span class="sd">                 Total inner iterations = 37</span>
<span class="sd">                 Total execution time = 0.2447 seconds</span>
<span class="sd">                Converting the latent factors to Numpy arrays.</span>


<span class="sd">            Below is an example on using a dense Numpy array as tensor X:</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                import numpy as np</span>
<span class="sd">                from pyCP_APR import CP_APR</span>

<span class="sd">                # X has the shape 10 x 30 x 40</span>
<span class="sd">                X = np.arange(1, 12001).reshape([10,30,40])</span>

<span class="sd">                cp_apr = CP_APR(n_iters=100, verbose=10, method=&#39;numpy&#39;)</span>
<span class="sd">                result = cp_apr.fit(tensor=X, Type=&#39;tensor&#39;, rank=2)</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                CP-APR (MU):</span>
<span class="sd">                Iter=1, Inner Iter=30, KKT Violation=0.244501, obj=534739600.517348, nViolations=0</span>
<span class="sd">                Exiting because all subproblems reached KKT tol.</span>
<span class="sd">                ===========================================</span>
<span class="sd">                 Final log-likelihood = 534841753.347965</span>
<span class="sd">                 Final least squares fit = 0.971281</span>
<span class="sd">                 Final KKT violation = 0.000091</span>
<span class="sd">                 Total inner iterations = 161</span>
<span class="sd">                 Total execution time = 1.1126 seconds</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                result.keys()</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                dict_keys([&#39;Factors&#39;, &#39;Weights&#39;])</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                M = result[&#39;Factors&#39;]</span>
<span class="sd">                Gamma = result[&#39;Weights&#39;]</span>

<span class="sd">                M_0 = M[&#39;0&#39;]</span>
<span class="sd">                Gamma_0 = Gamma[0]</span>

<span class="sd">                print(&#39;Component 0:&#39;, M_0, &#39;Gamma 0:&#39;, Gamma_0)</span>


<span class="sd">            .. code-block:: console</span>

<span class="sd">                Component 0:</span>
<span class="sd">                [[0.01002107 0.0099889 ]</span>
<span class="sd">                [0.03001639 0.02999136]</span>
<span class="sd">                [0.05001171 0.04999383]</span>
<span class="sd">                [0.07000709 0.0699962 ]</span>
<span class="sd">                [0.09000233 0.08999878]</span>
<span class="sd">                [0.10999784 0.11000099]</span>
<span class="sd">                [0.12999289 0.13000382]</span>
<span class="sd">                [0.14998825 0.15000623]</span>
<span class="sd">                [0.16998359 0.17000867]</span>
<span class="sd">                [0.18997884 0.19001122]] </span>
<span class="sd">                Gamma 0: 41633867.33685632</span>


<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Train M with multiple ranks</span>
        <span class="k">if</span> <span class="s1">&#39;rank&#39;</span> <span class="ow">in</span> <span class="n">parameters</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;rank&#39;</span><span class="p">],</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>

            <span class="n">Rank</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;rank&#39;</span><span class="p">]</span>

            <span class="c1"># Currently only supports 2 at a time for weighted prediction</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">Rank</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;Secify list of two ranks such as [2,4], or a single intiger rank.&quot;</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">Rank</span><span class="p">:</span>
                <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;rank&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">r</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">obj</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">obj</span>

            <span class="c1"># Save the rank</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">M</span><span class="o">.</span><span class="n">Rank</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span></div>

<div class="viewcode-block" id="CP_APR.predict_scores"><a class="viewcode-back" href="../../pyCP_APR.html#pyCP_APR.pyCP_APR.CP_APR.predict_scores">[docs]</a>    <span class="k">def</span> <span class="nf">predict_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The function call that can be used for classification of anomalies after fitting the tensor.</span>
<span class="sd">        The model will use the trained latent factors to generate the Poisson lambda scores corresponding to the given</span>
<span class="sd">        new coordinate.\n</span>
<span class="sd">        These lambda values are then used to calculate the p-values for classification of the entries.\n</span>
<span class="sd">        The lower p-value here is an indicator of an anomaly.\n</span>
<span class="sd">        Since the learned or expected behaviour during the training time is represented by the KRUSKAL tensor M,</span>
<span class="sd">        we can calculate how likely a new index to occur in M (i.e. M represents the average number of expected events for each coordinate).</span>
<span class="sd">        If two tensors trained during fitting, the prediction will weight the lambdas before calculating the p-values.</span>


<span class="sd">        .. note::</span>
<span class="sd">        </span>
<span class="sd">            * We find that using ensemble of tensors during prediction significantly reduces the false positive rates for anomaly detection as shown in [2].</span>
<span class="sd">            * Anomaly detection can be performed either using **predict_scores()**, or using **transform()** and **predict_probas()**. While using **transform()** and **predict_probas()** yields faster computation time and more established dimension fusion results, **predict_scores()** provides wider range of features for anomaly detection. </span>


<span class="sd">        .. warning:: </span>

<span class="sd">            * To use **predict_scores()**, **fit()** the model first.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coords : array</span>
<span class="sd">            Coordinates of the non-zero values.\n</span>
<span class="sd">        values : list</span>
<span class="sd">            List of non-zero values.\n</span>
<span class="sd">            Length must match the ``coords`` parameter length.\n</span>
<span class="sd">            Example binary links: ``array([1, 1, 1])``.</span>
<span class="sd">        from_matlab : boolean, optional</span>
<span class="sd">            If the dataset used in MATLAB as well, indices may start at 1 instead of 0. \n</span>
<span class="sd">            This parameter can be used to subtract 1 from the indices.\n</span>
<span class="sd">            The default is False.</span>
<span class="sd">        objective : string, optional</span>
<span class="sd">            ``objective=&#39;p_value&#39;`` calculates the Poisson p-value.\n</span>
<span class="sd">            Fusion ``objective`` options: &#39;p_value_fusion_harmonic&#39;, &#39;p_value_fusion_harmonic_observed&#39;, &#39;p_value_fusion_chi2&#39;,</span>
<span class="sd">            &#39;p_value_fusion_chi2_observed&#39;, &#39;p_value_fusion_arithmetic&#39;.\n</span>
<span class="sd">            If fusion is being used, specify the list of dimensions that are being targeted</span>
<span class="sd">            via the ``p_value_fusion_index`` parameter.\n</span>
<span class="sd">            Calculate log_likelihood of observing the link with ``objective=&#39;log_likelihood&#39;``.\n</span>
<span class="sd">            The default is ``objective=&#39;p_value&#39;``.</span>
<span class="sd">        ensemble_significance : list of length two, optional</span>
<span class="sd">            Weight of each tensor, if two is trained. Two is trained when ``rank=[r1,r2]`` during **pyCP_APR.CP_APR.fit()**</span>
<span class="sd">            where *r1* and *r2* are intiger ranks.</span>
<span class="sd">            The default is ``ensemble_significance=[0.1, 0.9]``.</span>
<span class="sd">        p_value_fusion_index : list, optional</span>
<span class="sd">            Fuses down to the target dimensions.\n</span>
<span class="sd">            List should contain the index of the dimensions to fuse.</span>
<span class="sd">            The default is ``p_value_fusion_index=[0]``.</span>

<span class="sd">            .. warning::</span>
<span class="sd">            </span>
<span class="sd">                Only used if fusion objective is being used.</span>

<span class="sd">        ignore_dimensions_indx : list, optional</span>
<span class="sd">            If used, the dimension numbers in the list will be ignored during the calculation of the lambdas.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        predictions : array</span>
<span class="sd">            Returns the prediction objective.\n</span>
<span class="sd">            For instance, if parameter was ``objective=&#39;p_value&#39;``, array of p-values are returned for each entry in the test tensor.</span>


<span class="sd">        .. note::</span>

<span class="sd">            **Example**</span>

<span class="sd">            Sample coordinate and value pair for a four dimensional tensor with 3 entries:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                # coordinates of 3 entries of 4 dimensional tensor</span>
<span class="sd">                coords = array([[    0,   961,     0,     0],</span>
<span class="sd">                                [    0,   961,  1742,     0],</span>
<span class="sd">                                [    0,   961,  2588,     0]])</span>
<span class="sd">                values = [1,2,1]</span>


<span class="sd">            Extracting the p-values from the test tensor:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from pyCP_APR.datasets import load_dataset</span>
<span class="sd">                from pyCP_APR import CP_APR</span>
<span class="sd">                from collections import OrderedDict</span>
<span class="sd">                import numpy as np</span>

<span class="sd">                data = load_dataset(name = &quot;TOY&quot;)</span>

<span class="sd">                # Training set</span>
<span class="sd">                coords_train = data[&#39;train_coords&#39;]</span>
<span class="sd">                nnz_train = data[&#39;train_count&#39;]</span>

<span class="sd">                # Test set</span>
<span class="sd">                coords_test = data[&#39;test_coords&#39;]</span>
<span class="sd">                nnz_test = data[&#39;test_count&#39;]</span>

<span class="sd">                # CP-APR model</span>
<span class="sd">                cp_apr = CP_APR(n_iters=10, random_state=42, verbose=1, method=&#39;torch&#39;, device=&#39;gpu&#39;, device_num=0)</span>

<span class="sd">                # factorize the tensor for ranks 1 and 4.</span>
<span class="sd">                M = cp_apr.fit(coords=coords_train, values=nnz_train, rank=[1,4])</span>

<span class="sd">                # calculate the p-values for the entries in the test set</span>
<span class="sd">                p_values = cp_apr.predict_scores(coords=coords_test, values=nnz_test)</span>


<span class="sd">            These p-values are also saved in the class variable, and can be found as follows:</span>


<span class="sd">            .. code-block:: python</span>

<span class="sd">                scores = list(cp_apr.prediction[&#39;p_value&#39;])</span>


<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Fit the tensor to aquire the latent factors first.&quot;</span>

        <span class="c1"># Prediction objective</span>
        <span class="k">if</span> <span class="s1">&#39;objective&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="s1">&#39;p_value&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;objective&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;objective&#39;</span><span class="p">]</span>

        <span class="c1"># Lambda calculation method</span>
        <span class="k">if</span> <span class="s1">&#39;ensemble_significance&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">ensemble_significance</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ensemble_significance</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ensemble_significance&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ensemble_significance&#39;</span><span class="p">]</span>

        <span class="c1"># If fusion is being performed</span>
        <span class="k">if</span> <span class="s1">&#39;p_value_fusion_index&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">p_value_fusion_index</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p_value_fusion_index</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;p_value_fusion_index&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;p_value_fusion_index&#39;</span><span class="p">]</span>

        <span class="c1"># if we are ignoring a dimension when calculating the lambdas</span>
        <span class="k">if</span> <span class="s1">&#39;ignore_dimensions_indx&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="n">ignore_dimensions_indx</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ignore_dimensions_indx</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ignore_dimensions_indx&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">parameters</span><span class="p">[</span><span class="s1">&#39;ignore_dimensions_indx&#39;</span><span class="p">]</span>


        <span class="c1"># If weighting two tensors during the calculation</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="n">PTA</span> <span class="o">=</span> <span class="n">PoissonTensorAnomaly</span><span class="p">(</span><span class="n">dimensions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;Factors&#39;</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;Weights&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
                                       <span class="n">lambda_method</span><span class="o">=</span><span class="s1">&#39;ensemble&#39;</span><span class="p">,</span>
                                       <span class="n">ensemble_dimensions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;Factors&#39;</span><span class="p">],</span>
                                       <span class="n">ensemble_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;Weights&#39;</span><span class="p">],</span>
                                       <span class="n">ensemble_significance</span><span class="o">=</span><span class="n">ensemble_significance</span><span class="p">,</span>
                                       <span class="n">ignore_dimensions_indx</span><span class="o">=</span><span class="n">ignore_dimensions_indx</span>
                                      <span class="p">)</span>
        <span class="c1"># Single tensor calculation</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">PTA</span> <span class="o">=</span> <span class="n">PoissonTensorAnomaly</span><span class="p">(</span><span class="n">dimensions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="s1">&#39;Factors&#39;</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">[</span><span class="s1">&#39;Weights&#39;</span><span class="p">],</span>
                                       <span class="n">objective</span><span class="o">=</span><span class="n">objective</span><span class="p">,</span>
                                       <span class="n">lambda_method</span><span class="o">=</span><span class="s1">&#39;single_tensor&#39;</span><span class="p">,</span>
                                       <span class="n">ignore_dimensions_indx</span><span class="o">=</span><span class="n">ignore_dimensions_indx</span>
                                      <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span> <span class="o">=</span> <span class="n">PTA</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">objective</span><span class="p">)]</span></div></div>
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Maksim E. Eren, Juston S. Moore, Erik Skau, Manish Bhattarai, Gopinath Chennupati, Boian S. Alexandrov
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2021, LANL.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>